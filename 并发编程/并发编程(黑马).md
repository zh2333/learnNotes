

# 并发编程

这里记得比较细碎,熬过面试完整的再看一遍



## 线程的状态

六个状态:创建,runnable,blocked,waiting,time_wating,term....

五个状态:创建,runnable,running,blocked,结束

## 线程安全

成员变量和静态变量是否线程安全?

* 如果他们没有被共享,则线程安全
* 如果他们被共享了,根据他们的状态是否能够改变,又分为两种情况:
  * 只有读操作,线程安全
  * **如果有读写操作**,考虑线程安全

局部变量是否线程安全?

* 局部变量是线程安全的
* 局部变量引用的对象则未必:
  * 如果该对象没有逃离方法的作用范围,则是线程安全的
  * **如果该对象逃离了方法的作用范围**,则需要考虑线程安全

保证线程安全?

* 使用private和final关键字修饰方法或者变量,这样子类就无法重写父类方法导致出现一些线程安全的问题



常见的线程安全类?

* String
* Integer

> String和Integer等都是不可变类,因为其内部 状态不可以改变,因此他们的方法都是线程安全的
>
> String使用final修饰的,体现了闭合原则,不会将引用暴露给外界
>
> Q:replace(),substring()等修改字符串的方法是线程安全的吗?
>
> A:是的,他们会创建一个新的字符串对象来修改,原来的对象并不会别修改

* StringBuffer

* Random

* Vector

* HashTable  

  put方法上加了synchronized关键字

* java.util.concurrent包下的类

> 上述类为什么是线程安全的?
>
> 1. 他们的每个方法是原子的
>
> 注:他们方法的组合不是原子的,方法的组合不是线程安全的

## syncronized

修饰静态方法:锁的是类,即使使用类创建了两个对象,也是互斥的

修饰成员方法:锁的是对象,必须使用同一个对象作为锁,否则会出现线程安全的问题

## monitor 

Monitor被翻译为监视器或管程,如果使用synchronized给对象上锁(重量级)之后,该对象头的MarkWord中就被设置指向Monitor对象的指针

Monitor的结构如下:

![image-20200410163903315](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200410163903315.png)

当执行加锁操作(锁对象为obj),会将obj锁对象和操作系统提供的Monitor相关联(MarkWord中的)

![image-20200410164605056](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200410164605056.png)

ptr_to_heavyweight_monitor是一个指针,指向了Monitor

随后thread2会变成Monitor的所有者

如果此时又来了一个Thread1,这个线程也会关联到这个Monitor,但是会进入Monitor的等待队列,而不是与owner关联

Thread2离开后,Monitor会唤醒等待的线程竞争成为新的owner

![image-20200410165119244](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200410165119244.png)

> synchronized必须是进入同一个对象的monitor才有上述效果
>
> 不加synchronized的对象不会关联监视器,不遵从以上规则
>
> synchronized修饰的代码块发生异常时会主动的释放锁

Monitor就是重量级锁,如果线程每次执行同步代码块时,都使用synchronized关键字使用重量级锁的话,性能会很低.因此引入了偏向锁和轻量级锁,并加入了自锁机制来保证性能的提升



加锁的原始过程:

刚开始没有任何持有锁对象,这时有一个线程来了,成功加锁(线程的栈帧中生成一个锁记录,用来指向锁对象,并将锁对象中的MarkWord中的锁代码由01--无状态,替换为00,轻量级锁).之后如果有新线程过来,会尝试替换锁对象头中的MarkWOrd,发现已经被替换过了(不是01),所以就加锁失败,此时锁就会膨胀为重量级锁(原来的锁对象也是存在的,此时这个锁对象会指向重量级锁),这个线程就会进入重量级锁(Monitor)的EntryList中阻塞.当原来的线程来解锁时,发现锁已经膨胀了,不是原来的轻量级锁了,就会按照锁对象指向的地址,找到重量级锁,将其解锁(将owner置为null),随后唤醒阻塞中的线程.

![image-20200410211954033](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200410211954033.png)

![image-20200410212015820](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200410212015820.png)

![image-20200410212243101](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200410212243101.png)

> 这个替换锁对象头中MarkWord的锁代码的操作称之为CAS



上述过程存在两个可以优化的地方:

1. 如果没有线程竞争锁,那么原始线程再次来加锁的时候,会新产生一个Lock Record(作为锁重入记录),并尝试CAS(失败,)浪费性能.
2. 第二个线程在尝试加锁时,失败了,会立即进入阻塞状态,引起上下文的切换,这也是很耗性能的.

为此引入了两个优化:

1. 针对第一个--引入了偏向锁

   java6中引入了偏向锁的机制,只有在第一次使用CAS时将线程ID设置到对象头的MarkWord中,之后发现这个线程ID 是自己的就表示没有竞争,不用重新CAS

2. 针对第二个--引入了自旋

   尝试加锁失败时,虽然升级为重量级锁,但是不立即进入阻塞状态,而是在之后的一段时间内不断尝试,过了一段时间如果还是加锁失败,就进入阻塞状态.
   
   > 自旋对于多核才是有意义的,单核的情况下,线程虽然没有进入阻塞,但是没有分配到时间片,所以会进入可运行状态,导致上下文切换
   
   

## ReentranLock(基于AQS)

相对于synchronized,它具备如下特点:

* 可中断

* 可以设置超时时间

  一段时间内抢不大锁,就去干别的事

* 可以设置为公平锁

* 支持多个条件变量

**可重入** 

可重入指的是同一个线程首次获得了这把锁,那么因为他是这把锁的拥有者,因此有权利再次获取这把锁.如果不是可重入锁,那么第二次获得锁时,自己也会被锁挡住

基本使用:

```java
reentranLock.lock();
try {
	//临界区    
}finally{
    //释放锁
    reentranLock.unlock();
}
```

lock.lockInterruptibly();//在等待锁的时候可以被打断(你别等了!劝说放弃等待锁,防止死等)

**锁超时**

lock.tryLock(timeLimit)方法

等待一定时间就主动不再等待

> 有点像打破死锁的四个必要条件中的--不可剥夺条件,如果拿到了一个,接着拿不到另一个就释放手中已有的资源--解决哲学家问题

**公平锁/非公平锁**

ReentranLock默认是非公平锁--即需要竞争,而不是按照进入阻塞队列的时间顺序获得锁

> 公平锁一般没有必要,会降低并发度

**条件变量**

synchronized也支持条件变量,当条件不足时进入waitSet等待

ReentranLock的条件变量比synchronized强大之处在于,它是支持多条件变量的

* synchronized那些不满足条件的线程都会在一件休息室等消息
* ReentranLock支持多间休息室,有专门等烟的休息室,专门等早餐的休息室等等

> 使用lock.newCondition()创建不同的条件变量
>
> condition.await()进入休息室等待
>
> condition.signal()唤醒对应休息室中的线程



**实现原理**

非公平锁/公平锁(继承自AQS)

1. 非公平锁

   ![image-20200412094950701](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412094950701.png)

   ![image-20200412095142092](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412095142092.png)

   ![image-20200412100640568](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412100640568.png)

   ![image-20200412100918764](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412100918764.png)

   ![image-20200412101114022](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412101114022.png)

   

   **可重入原理**

   当一个线程持有锁,之后再次来获取锁时会检查状态,getState()为1,它就会把state++,释放锁的时候会先将state--,并没有真正的释放锁,只有当state减为0时,才会真正解开锁

   

   **可打断原理**

   默认不可打断模式

   在次模式下,即使它被打断,仍会驻留在AQS队列中,等获得锁之后才能继续运行(只是打断标记被设置为true)

   可打断模式

   抛出异常

   

   **公平锁原理**

   

   **条件变量实现原理**

   每个条件变量其实就是一个等待队列,其实现类是ConditionObject.

   每个等待队列其实就是双向链表

   * await流程

     ![image-20200412110033519](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412110033519.png)

     ![image-20200412110330811](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412110330811.png)

     fullRelease就是会获取当前state的值(防止锁重入),然后释放掉同步器上所有的锁,thread-0进入park状态

     接下来唤醒AQS队列中的下一个节点(unpark)

     ![image-20200412110545466](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412110545466.png)

   * signal流程

     取得等待队列中的**第一个Node**,即Thread-0所在的Node,完了唤醒之后将该node加入到AQS队列尾部,重新排队,将Thread-0的waitStatus改为0,Thread-3的waitStatus改为-1(thread-3负责唤醒Thread-0)

     ![image-20200412111356602](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412111356602.png)

   

**读写锁**

当读操作远远高于写操作时,这时使用`读写锁`让`读-读`可以并发,提高性能(但是写-写和读写还是互斥的)

类似于数据库中的select....from...lock in share mode

提供一个数据库容器类内部分别使用读锁保护数据的read()方法,写锁保护数据的write()方法

> 1. 读锁不支持条件变量
> 2. 重入时不支持升级: 在持有读锁的情况下不能够再获取写锁(必须先释放读锁才能获取到写锁)
> 3. 重入时支持降级操作:持有锁的情况下可以获取读锁

**读写锁原理**

读写锁用的是同一个Sync同步器,因此等待队列,state等也是同一个.写锁占据state的低16位,而读锁占据state的高16位

![image-20200412144551143](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412144551143.png)

上图中,t1加了读锁,t2,t3想加读锁,结果被阻塞了(状态是AQS状态中的shared--`共享状态`),t4想要加写锁,也是被阻塞了(状态是EX,`独占状态`)

> 之所以是两种状态,是因为他们的解锁行为是不同的.t1结束运行后,head会唤醒t2来执行,t2会接着判断他的下一个节点是否是shared(因为t2也是shared,而读-读是可以并发的),如果是,则把t3一起唤醒,两个一起去读



## volatile

volatile的底层实现原理是**内存屏障**,Memory Barrier

* 对volatile变量的写指令后会加入写屏障

* 对volatile变量的读指令前会加入读屏障

> 写屏障:保证在该屏障之前的,对共享变量的改动,都同步到主存当中
>
> 读屏障:保证在该屏障之后,对共享变量的读取,加载的是主存中的最新数据

**有序性**

* 写屏障会确保指令重排时,不会将写屏障之前的代码排在写屏障之后
* 读屏障会确保指令重排时,不会将读屏障之后的代码排在读屏障之前

> volatile解决的是有序性和可见性,不能保证原子性,synchronized可以保证有序性,可见性和原子性

**dcl**

double-checking locking,这种思想的典型应用是在单例模式的实现中.如果不使用这种机制,线程每次尝试创建单例都会加锁,而事实上,只有第一次需要加锁,后面线程在尝试创建实例时会发现实例已经存在就不会创建了.

```java
/**
只有第一次创建实例时需要加锁,如果实例存在,则不需要进入同步代码快
*/
public final class Singleton {
    private Singleton() {}
    private static Singleton INSTANCE = null;
    public static Singleton getInstance() {
        if(INSTANCE == null) {
            synchronized(Singleton.class) {
                if(INSTANCE == null) {
                    INSTANCE = new Singleton();
                }
            }
        }
        return INSTANCE;
    }
}
```

> 特点:
>
> 1. 懒惰实例化
> 2. 首次使用getInstance()才使用synchronized加锁,后序使用无需加锁

上述代码其实是有问题的,INSTANCE = new Singleton();这句代码在编译成字节码是会发生指令重排,即,先进行复制操作(没有构造完全的实例),再调用构造方法构造实例,如果这时来了一个另一个线程,它判断INSTANCE是否为空,发现,不为空,就会返回一个实例(没有构造完毕的实例)

<img src="C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200411141058264.png" alt="image-20200411141058264" style="zoom: 67%;" />

如果在声明INSTANCE变量的时候加上关键字volatile,就会禁止指令重排序,保证赋值完之后第二个线程拿到的INSTANCE是构造完成的

<img src="C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200411142429901.png" alt="image-20200411142429901" style="zoom:67%;" />

**happens-before**

happens-before规定了对共享变量的写操作对其他线程的读操作课件,它是可见性与有序性的一套规则总结

* 一个线程对变量的写,对于接下来竞争同一个锁的其他线程的读可见(synchronized)
* 线程对volatile变量的写,对接下来其他线程对该变量的读可见(volatile)
* 线程开始(start)之前,对变量的写,对该线程开始后对该变量的读可见
* 线程结束之前对变量的写,对其他线程得知它结束后的读可见
* 对变量默认值(0,null,false)的写,对其他线程对该变量的读可见
* 传递性

## CAS

compare and set / compare and swap,是原子操作

比较并交换,不断尝试直至成功(不断比较---自旋,但是CAS != 自旋)

CAS命令的底层是lock cmpxchg指令(锁住总线)

**CAS特点**

结合CAS和volatile可以实现无锁并发,适用于线程数少,多核CPU的场景

* CAS基于乐观锁的思想,不怕别的线程修改变量,即使修改了,自己再尝试一次
* synchronized基于悲观锁的思想:防止别的线程来修改变量,我改完了你们再改
* CAS体现的是无锁并发,无阻塞并发
  * 没有使用synchronized,所以线程不会陷入阻塞
  * 如果竞争激烈,重试必然频繁,反而效率会降低

## 线程池

![image-20200411150535145](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200411150535145.png)

**自定义线程池**





**拒绝策略**

* 死等
* 带超时时间的等待
* 让调用者放弃执行任务
* 让调用者抛出异常
* 让调用者自己执行任务

> 策略模式:把具体的操作抽象成一个接口,具体的实现由调用者传递进来

**jdk提供的线程池**

![image-20200411202403373](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200411202403373.png)

1) 线程池状态

ThreadPoolExecutor使用int的高三位来表示线程 池状态,低32位表示线程数量

| **状态名** | **高3位** | **接受新任务** | **处理阻塞任务队列** |                      **说明**                       |      |
| :--------: | --------- | :------------: | :------------------: | :-------------------------------------------------: | ---- |
|  RUNNING   | 111       |       Y        |          Y           |                                                     |      |
|  SHUTDOWN  | 000       |       N        |          Y           | 不会接受新的任务,但是会将任务队列中的剩余任务处理完 |      |
|    STOP    | 001       |       N        |          N           |       会中断正在执行的任务,并抛弃阻塞队列任务       |      |
|  TIDYING   | 010       |                |                      |       任务全执行完毕,活动线程为0即将进入终结        |      |
| TREMINATED | 011       |                |                      |                      终结状态                       |      |

>  为什么用32位来表示两个信息,而不是用两个变量分别表示
>
> 这些信息存储在一个原子变量中,目的是将线程池状态与线程个数合二为一,这样就可以用一次cas原子操作进行赋值

2)构造方法

```java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler)
```

* corePoolSize:核心线程数目
* maximumPoolSize:最大线程数
* keepAliveTime:线程生存时间(针对救急线程)
* unit:时间单位(针对救急线程)
* workQueue:阻塞队列
* threadFactory:线程工厂--可以为线程创建时起个名字
* Handler:拒绝策略

> 核心线程没有生存时间,会一直运行,救急线程有生存时间
>
> 救急线程仍然不够时会执行拒绝策略
>
> 救急线程数量:maxPoolSize - corePoolSize

**jdk中提供的拒绝策略**

* 让调用者抛出RejectExecutionException,默认
* 让调用者运行任务
* 放弃本次任务
* 放弃队列中最早的任务,本任务取而代之



3)newFixedThreadPool

* 核心线程数 == 最大线程数(没有救急线程)
* 阻塞队列是无界的,可以放任意数量的任务

> 适用于任务量已知,相对耗时的任务

4)newCachedThreadPool

* 核心线程数为0,最大线程数为Integer.MAX_VALUE,救急线程的空闲生存时间是60s,意味着
  * 这个线程池创建出来的全部都是救急线程(空闲60秒后可以回收)
  * 救急线程可以无限创建
* 队列采用同步队列实现(它的特点是没有容量)

> 整个线程池表现为线程数会根据任务量不断增长,没有上限,当任务执行完毕,空闲一分钟之后释放线程
>
> 适合任务数比较密集,但是每个任务执行时间较短的情况

5)newSingleThreadExecutor

使用场景:

希望多个任务排队执行.线程数量固定为1,任务数固定为1,任务数多于1时,会放入无界队列排队.任务执行完毕后,这唯一的线程也不会被释放

区别:

* 自己创建一个单线程串行执行任务,如果任务执行失败而终止那么没有任何补救措施,而线程池还会创建一个新的线程
* 线程个数始终为1,不能修改
* newFixedThreadPool(1)初始时为1,以后还可以修改



**使用**

```java
ExecutorService service = Executors.newFixedThreadPool(2);
service.submit(() -> {
    //执行任务
});
```





## JUC

### AQS

全称是AbstractQueuedSynchroized, 是阻塞式锁和相关的同步器工具的框架

特点:

* 用state属性来表示资源的状态(`独享模式`和`共享模式`),子类需要定义如何维护这个状态,控制获取锁和释放锁
* 提供了基于FIFO的等待队列,类似于Monitor的EntryList
* 条件变量来实现等待,唤醒机制,支持多个条件变量,类似于Monitor的WaitSet

锁机制都是基于AQS.加锁之前会获取锁的状态,getState,如果是0,表示没有线程持有锁,如果是1,表示有线程持有锁,线程就会进入等待队列等待(带有头结点的链表).当锁被释放后,头结点就会唤醒紧邻着它的线程节点,让他去运行.



### Semaphore(基于AQS)

信号量,用来限制能同时访问共享资源的线程上限

```java
Semaphore semaphore = new Semaphore(permit: 3);
```

应用:

1. 使用Semaphore限流,在访问高峰期,让请求线程阻塞,高峰过去再释放许可
2. 用Semaphore实现简单连接池

> 限制的是线程数量而不是资源数

**原理**

该开始5个线程过来获取资源

![image-20200412155200895](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412155200895.png)假设1,2,4线程竞争成功,而0,3线程竞争失败,进入AQS队列park阻塞

![image-20200412155712539](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412155712539.png)

接下来4线程释放了permits,0线程竞争成功,permit的数量再次被减为零,接下来会继续unpark3线程,由于permits,因此3线程在尝试不成功后再次进入park状态

![image-20200412160245936](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412160245936.png)



### CountDownLatch

倒计时锁,用来进行线程同步协作,等待所有线程完成倒计时

其中构造参数用来初始化等待计数,await()用来等待计数归零,countDown()用来让计数减一

> countDown()不同于jion()
>
> join()是等待线程结束运行,而countDown是等待计数减为零
>
> 在线程池的应用场景下,使用countDown()比join()更适用

应用场景:王者荣耀5V5要等待所用的玩家进入才可以进入游戏



### CyclicBarrier

CountLaunch存在一个问题就是 创建的CountdownLatch对象不可重用,在一轮任务执行完之后就不能继续在下一轮任务中重用,因为计数已经减为零了

循环栅栏,用来进行线程协作,等待线程满足某个计数时,构造时设置[计数个数],每个线程执行到某个需要同步的时刻调用await方法等待,当等待的线程数满足计数个数时,继续执行

> 计数值可以恢复到初始值

await()等待,类似于countDown方法,会将计数值减一



## 线程安全集合类

![image-20200412170956023](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412170956023.png)

遗留的安全集合:

hashtable: put和get方法都加了synchronized关键字,性能很低

修饰的安全集合: 使用collections的方法修饰(装饰模式)

![image-20200412192225397](C:\Users\张恒\Desktop\Javaweb\L\并发编程\image-20200412192225397.png)

JUC包下的集合类:

* Blocking: 大部分基于锁实现,并提供用来阻塞的方法

* CopyOnWrite: 修改开销大,适合读多写少的场景

* Concurrent:

  * 内部很多操作都用cas优化,可以提高吞吐量

  * 弱一致性

    * 如果容器发生了修改,迭代器可以继续进行遍历,这时内容是旧的
    * 求大小弱一致性,size操作未必是100%准确
    * 读取弱一致性

    对于非安全,如果遍历时发生而来修改,使用fail-fast机制可以让遍历立刻失败

java7之前采用的是头插法来解决冲突,头插法会导致死链问题.现在有两个线程,一个HashMap,HashMap中此时有12个元素(桶大小为16),因此如果接下来两个线程向HashMap中插入数据会引起桶的扩容(两个都会).假设hashmap中此时有三个数据1,35,16,他们三个是链在一起的,像这样1->35->16(这三个元素都在一号桶上),此时thread0-1插入了一个新的数据,导致的桶的扩容和rehash,rehash之后,一号桶上的元素变成了35->1->null,此时thread-0过来 插入 数据同样导致rehash,开始遍历一号桶,把1插入到一号桶上,一号桶上的数据由35->1 ===>1->35->1->null,接下来继续将35插入到头部,变成35->1->35->1->null,接下来会一直循环不停的插入这两个元素

> JDK8后采用了尾插法,保证了扩容前后数据顺序的一致性,但是仍然不能保证安全扩容,还会出现别的问题,比如扩容丢失数据

**ConcurrentHashMap**

